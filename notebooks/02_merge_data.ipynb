{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths for individual parts and combined part. Change raw_data_path and inter_data_path as needed.\n",
    "# There should be a '/' at the end of raw and inter_data_path\n",
    "\n",
    "raw_data_path = \"C:/Users/User/Documents/MITB/MITB Term 5/Recommender Systems/Group Project/cs608-p2-experiments/data/01_raw/\"\n",
    "inter_data_path = \"C:/Users/User/Documents/MITB/MITB Term 5/Recommender Systems/Group Project/cs608-p2-experiments/data/02_intermediate/\"\n",
    "primary_path = \"C:/Users/User/Documents/MITB/MITB Term 5/Recommender Systems/Group Project/cs608-p2-experiments/data/03_primary/\"\n",
    "\n",
    "damien_scrape = raw_data_path + \"anime_scrapy_damien.csv\"\n",
    "leroy_scrape = raw_data_path + \"anime_scrapy_leroy.csv\"\n",
    "rosamund_scrape = raw_data_path + \"anime_scrapy_rosamund.csv\"\n",
    "kenneth_scrape = raw_data_path + \"anime_scrapy_kenneth.csv\"\n",
    "\n",
    "all_scrape_path = inter_data_path + \"anime_scrapy_all.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating the 4 partitions together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_and_write_scraped_partitions(output_path: str, *args: str) -> pd.DataFrame:\n",
    "    \"\"\"combines the partitioned scraped dataframes and writes the merged dataframe into a csv file.\n",
    "\n",
    "    Args:\n",
    "        output_path (str): Path to write the merged DataFrame to\n",
    "        *args (str): Arbitrary number of filepaths to pandas DataFrames to concatenate.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame obtained by concatenating the input DataFrames row-wise.\n",
    "    \n",
    "    \"\"\"\n",
    "    merged_df = None\n",
    "    for df_path in args:\n",
    "        df = pd.read_csv(df_path, sep=\"|\")\n",
    "        if not merged_df:\n",
    "            merged_df = df\n",
    "        else:\n",
    "            merged_df = pd.concat([merged_df, df], axis=0, ignore_index=True)\n",
    "    merged_df.to_csv(output_path, sep=\"|\", index=False)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scrape_df = concatenate_and_write_scraped_partitions(all_scrape_path, damien_scrape, leroy_scrape, rosamund_scrape, kenneth_scrape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scrape_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scrape_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join anime features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_path = raw_data_path + \"anime.csv\"\n",
    "joined_path = primary_path + \"primary_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as I cannot see how sparse the data is when writing this code, I will preliminarily set the join to left, \n",
    "# but we can set it to outer or inner if they make more sense\n",
    "\n",
    "how = \"left\"\n",
    "on = \"anime_id\" # shared column from anime.csv and scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the data we got from kaggle and the data we got from scraping \n",
    "def join_kaggle_and_scraped_data(\n",
    "    kaggle_anime_data: str, \n",
    "    scraped_data: str, \n",
    "    how: str,\n",
    "    on, str,\n",
    "    joined_path: str,\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"Joins Kaggle anime data and scraped anime data into a single DataFrame.\n",
    "\n",
    "    This function reads Kaggle anime data from a CSV file and scraped anime data from another CSV file,\n",
    "    then performs a merge operation on them based on the specified columns and join type. The resulting\n",
    "    DataFrame is saved to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        kaggle_anime_data (str): Path to the CSV file containing Kaggle anime data.\n",
    "        scraped_data (str): Path to the CSV file containing scraped anime data.\n",
    "        how (str): Type of merge to be performed. Options are 'left', 'right', 'outer', 'inner'.\n",
    "        on (str): Column or index level names to join on. These must be found in both DataFrames.\n",
    "        joined_path (str): Path to save the resulting merged DataFrame as a CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The resulting merged DataFrame.\n",
    "    \n",
    "    \"\"\"\n",
    "    left_df = pd.read_csv(kaggle_anime_data)\n",
    "    right_df = pd.read_csv(scraped_data, sep=\"|\")\n",
    "    joined_df = pd.merge(left_df, right_df, how=how, on=on, suffixes=(None, \"_scrape\"))\n",
    "    joined_df.to_csv(joined_path, sep=\"|\", index=False)\n",
    "    return joined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data = join_kaggle_and_scraped_data(\n",
    "    kaggle_anime_data=anime_path\n",
    "    scraped_data=all_scrape_path, \n",
    "    how=how,\n",
    "    on=on,\n",
    "    joined_path=joined_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS608_RecommenderSystems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
